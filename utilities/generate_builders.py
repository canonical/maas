#!/usr/bin/env python3

# Copyright 2025 Canonical Ltd.  This software is licensed under the
# GNU Affero General Public License version 3 (see the file LICENSE).

"""Auto generate builders for domain models.

It generates a builder in src/maasservicelayer/builders/ for the corresponding
model in src/maasservicelayer/models.

To generate a builder for a model, just decorate the model with
`generate_builder` from src/maasservicelayer/models/base.py.

HEADS UP: this is currently tested with SQLAlchemy 1.x, we might want to revise
this when we switch to 2.x.
"""

from abc import ABC, abstractmethod
import argparse
import dataclasses
import importlib
import inspect
import os
import re
import sys
from types import FunctionType, ModuleType
from typing import get_args, get_origin, Self, TypeVar, Union

from pydantic.fields import ModelField

MODELS_PATH = "src/maasservicelayer/models"
BUILDERS_PATH = "src/maasservicelayer/builders"
MODELS_MODULE = "maasservicelayer.models"
BUILDERS_MODULE = "maasservicelayer.builders"

HEADER_TEMPLATE = """\
# Copyright 2025 Canonical Ltd.  This software is licensed under the
# GNU Affero General Public License version 3 (see the file LICENSE).

{import_stmts}

"""

CLASS_TEMPLATE = """

class {model_name}(ResourceBuilder):
    \"\"\"Autogenerated from utilities/generate_builders.py.

    You can still add your custom methods here, they won't be overwritten by
    the generated code.
    \"\"\"

{fields_definitions}

{builder_methods}

"""

EXCLUDED_FIELDS = ["id"]

MODELS_BASE = "maasservicelayer.models.base"
sys.path.insert(0, "./src")
try:
    base = importlib.import_module(MODELS_BASE)
    Unset = vars(base)["Unset"]
    UNSET = vars(base)["UNSET"]
    ResourceBuilder = vars(base)["ResourceBuilder"]
except KeyError as e:
    print(f"{e} not found in {MODELS_BASE}")
    sys.exit(1)


def default_imports() -> set:
    imports = set()
    imports.add("from typing import Union")
    imports.add("from pydantic import Field")
    imports.add(
        "from maasservicelayer.models.base import ResourceBuilder, UNSET, Unset"
    )
    return imports


def process_string(s) -> str:
    """Preprocess the `annotation` or `type_` field of a ModelField.

    This function:
        - removes all the not wanted chars in e.g. <class 'x'> and <enum 'x'>
        - translates `NoneType` to `None`
        - removes all modules' prefixes
    """
    s = (
        str(s)
        .removeprefix("<class '")
        .removeprefix("<enum '")
        .removesuffix("'>")
    )
    # while dealing with pydantic modelfield, sometimes None is expressed as NoneType
    s = s.replace("NoneType", "None")
    # remove all module prefixes
    s = re.sub(r"\w*\.", "", s)
    return s


def get_module_name_for_type(type_) -> str:
    # workaround for Literal["foo"]
    if isinstance(type_, str):
        return "builtins"
    module = inspect.getmodule(type_)
    assert module is not None, f"Could not find module for {type_}"
    return module.__name__


def add_imports(module_name: str, field: str, imports: set):
    if module_name not in ["builtins", "types"]:
        if len(module_name.split(".")) >= 1:
            imports.add(f"from {module_name} import {field}")
        else:
            imports.add(f"import {module_name}")


def handle_composite_type(type_, imports: set):
    outer = get_origin(type_)
    module_name = get_module_name_for_type(outer)
    add_imports(module_name, process_string(outer), imports)

    inner = get_args(type_)
    for inner_type in inner:
        if get_origin(inner_type) is not None:
            handle_composite_type(inner_type, imports)
        else:
            handle_simple_type(inner_type, imports)


def handle_simple_type(type_, imports: set):
    module_name = get_module_name_for_type(type_)
    add_imports(module_name, process_string(type_), imports)


def process_field(field: ModelField, imports: set) -> ModelField:
    """Modifies the field and updates the import statements.

    Updates the type_ and annotation of the field, making it a Union of the
    already present value and Unset.
    It also set the required attribute to False and updated the model_config
    with the config of ResourceBuilder (in order to allow for arbitrary types).
    """
    if get_origin(field.annotation) is not None:
        handle_composite_type(field.annotation, imports)
    else:
        handle_simple_type(field.annotation, imports)

    field.type_ = Union[field.type_, Unset]
    field.annotation = Union[field.annotation, Unset]
    field.default = UNSET
    field.required = False
    field.model_config = ResourceBuilder.__config__
    return field


@dataclasses.dataclass(kw_only=True)
class GenericModel(ABC):
    name: str
    fields: list[ModelField]
    model_imports: set = dataclasses.field(default_factory=default_imports)


T = TypeVar("T", bound=GenericModel)


@dataclasses.dataclass(kw_only=True)
class GenericModule[T](ABC):
    filename: str
    models: list[T]
    module_imports: set = dataclasses.field(default_factory=default_imports)

    @classmethod
    @abstractmethod
    def from_file(cls, module: ModuleType, filename: str) -> Self:
        pass


M = TypeVar("M", bound=GenericModule)


@dataclasses.dataclass(kw_only=True)
class GenericCollection[M](ABC):
    modules: list[M]
    module_prefix: str

    @classmethod
    @abstractmethod
    def from_path(cls, path: str) -> Self:
        pass

    def pop_module_with_filename(self, filename: str) -> M | None:
        for i, m in enumerate(self.modules):
            if m.filename == filename:
                return self.modules.pop(i)
        return None

    def __iter__(self):
        for module in self.modules:
            yield module

    def __len__(self):
        return len(self.modules)


@dataclasses.dataclass(kw_only=True)
class BuilderModel(GenericModel):
    methods: list[tuple[str, FunctionType]] = dataclasses.field(
        default_factory=list
    )

    def to_file(self) -> str:
        field_lines = ""
        for field in sorted(self.fields, key=lambda f: f.name):
            field_lines += f"    {field.name}: {process_string(str(field.annotation))} = Field(default=UNSET, required=False)\n"
        method_lines = ""
        for method_name, method_obj in self.methods:
            if method_name.startswith("__"):
                continue
            method_lines += "".join(inspect.getsourcelines(method_obj)[0])
        return CLASS_TEMPLATE.format(
            model_name=self.name,
            fields_definitions=field_lines,
            builder_methods=method_lines,
        )

    def update_methods(self, methods):
        self.methods = methods

    def __eq__(self, other) -> bool:
        """Compare the fields to check if the two model differs."""
        if isinstance(other, BuilderModel):
            if self.name != other.name:
                return False
            fields_self = sorted(self.fields, key=lambda m: m.name)
            fields_other = sorted(other.fields, key=lambda m: m.name)
            if len(fields_self) != len(fields_other):
                return False
            for f1, f2 in zip(fields_self, fields_other):
                if f1.name != f2.name or f1.annotation != f2.annotation:
                    return False

            return True
        return False


@dataclasses.dataclass(kw_only=True)
class BuilderModule(GenericModule[BuilderModel]):
    @classmethod
    def from_file(cls, module: ModuleType, filename: str):
        model_classes = inspect.getmembers(
            module,
            lambda x: inspect.isclass and inspect.getmodule(x) == module,
        )
        models = []
        for name, class_ in model_classes:
            if name.endswith("Builder") and name != "ResourceBuilder":
                builder_methods = inspect.getmembers(
                    class_,
                    lambda x: inspect.isfunction(x)
                    and not getattr(ResourceBuilder, x.__name__, False),
                )
                fields = list(class_.__fields__.values())
                fields = [f for f in fields if f.name not in EXCLUDED_FIELDS]
                models.append(
                    BuilderModel(
                        name=name,
                        fields=fields,
                        methods=builder_methods,
                    )
                )
        return cls(filename=filename, models=models)

    def to_file(self) -> str:
        class_defs = ""
        for class_ in self.models:
            class_defs += class_.to_file()
            self.module_imports = self.module_imports | class_.model_imports
        imports = "\n".join(self.module_imports)
        header = HEADER_TEMPLATE.format(import_stmts=imports)
        return header + class_defs

    def update_models_methods_from_other(self, other):
        if self.filename != other.filename:
            raise Exception("Cannot update models of different modules.")
        models_self = sorted(self.models, key=lambda m: m.name)
        models_other = sorted(other.models, key=lambda m: m.name)
        for model, other_model in zip(models_self, models_other):
            model.update_methods(other_model.methods)

    def __eq__(self, other) -> bool:
        models_self = sorted(self.models, key=lambda m: m.name)
        models_other = sorted(other.models, key=lambda m: m.name)
        if len(models_self) != len(models_other):
            return False
        for m1, m2 in zip(models_self, models_other):
            if m1 != m2:
                return False
        return True


@dataclasses.dataclass(kw_only=True)
class BuilderCollection(GenericCollection[BuilderModule]):
    module_prefix: str = BUILDERS_MODULE

    @classmethod
    def from_path(cls, path: str):
        modules = []
        for filename in os.listdir(path):
            modulename = f"{cls.module_prefix}.{filename.removesuffix('.py')}"
            module = importlib.import_module(modulename)
            builder_module = BuilderModule.from_file(module, filename)
            if len(builder_module.models) == 0:
                continue
            modules.append(builder_module)
        return cls(modules=modules)

    def __contains__(self, filename: str):
        for m in self.modules:
            if m.filename == filename:
                return True
        return False


@dataclasses.dataclass(kw_only=True)
class DomainModel(GenericModel):
    def to_builder(self) -> BuilderModel:
        fields = []
        imports = default_imports()
        for field in sorted(self.fields, key=lambda f: f.name):
            fields.append(process_field(field, imports))
        return BuilderModel(
            name=f"{self.name}Builder", fields=fields, model_imports=imports
        )


@dataclasses.dataclass(kw_only=True)
class DomainModule(GenericModule[DomainModel]):
    @classmethod
    def from_file(cls, module: ModuleType, filename: str):
        model_classes = inspect.getmembers(
            module,
            lambda x: getattr(x, "__generate_builder__", False)
            and inspect.getmodule(x) == module,
        )
        models = []
        for name, class_ in model_classes:
            fields = list(class_.__fields__.values())
            fields = [f for f in fields if f.name not in EXCLUDED_FIELDS]
            models.append(DomainModel(name=name, fields=fields))

        return cls(filename=filename, models=models)

    def to_builder_module(self) -> BuilderModule:
        builders = []
        for model in self.models:
            builders.append(model.to_builder())
        return BuilderModule(filename=self.filename, models=builders)


@dataclasses.dataclass(kw_only=True)
class DomainCollection(GenericCollection[DomainModule]):
    module_prefix: str = MODELS_MODULE

    @classmethod
    def from_path(cls, path: str):
        modules = []
        for filename in os.listdir(path):
            modulename = f"{cls.module_prefix}.{filename.removesuffix('.py')}"
            module = importlib.import_module(modulename)
            domain_module = DomainModule.from_file(module, filename)
            if len(domain_module.models) == 0:
                # we don't have to generate anything
                continue
            modules.append(domain_module)
        return cls(modules=modules)


def write_builder_file(filename: str, data: str):
    with open(f"{BUILDERS_PATH}/{filename}", "w") as f:
        f.write(data)


def delete_builder_file(filename: str):
    os.remove(f"{BUILDERS_PATH}/{filename}")


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("-c", "--check", action="store_true")
    args = parser.parse_args()

    # domain collection and builder collection
    domain_collection = DomainCollection.from_path(MODELS_PATH)
    builder_collection = BuilderCollection.from_path(BUILDERS_PATH)

    to_write = {}
    to_delete = []

    for domain_module in domain_collection:
        generated_builder_module = domain_module.to_builder_module()
        filename = generated_builder_module.filename
        existing_builder_module = builder_collection.pop_module_with_filename(
            filename
        )

        if existing_builder_module is None:
            to_write[filename] = generated_builder_module.to_file()
        elif generated_builder_module != existing_builder_module:
            generated_builder_module.update_models_methods_from_other(
                existing_builder_module
            )
            to_write[filename] = generated_builder_module.to_file()

    # if there are other builders not processed, delete them
    for module in builder_collection:
        to_delete.append(module.filename)

    if args.check:
        if to_write or to_delete:
            if to_write:
                print(
                    f"Builders {list(to_write.keys())} must be re-generated."
                )
            if to_delete:
                print(f"Builders {to_delete} must be deleted.")
            print("Run `make generate-builders`.")
            sys.exit(1)
    else:
        for file, data in to_write.items():
            write_builder_file(file, data)
        for file in to_delete:
            delete_builder_file(file)


if __name__ == "__main__":
    main()
